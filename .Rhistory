out_phylo_6_7k <- validateTaxa(phylo_species$x[6001:7000])
out_phylo_7_8k <- validateTaxa(phylo_species$x[7001:8000])
out_phylo_8_9k <- validateTaxa(phylo_species$x[8001:9000])
out_phylo_9k <- validateTaxa(phylo_species$x[9001:9478])
out_phylo_4_5k <- validateTaxa(phylo_species$x[4001:5000])
out_phylo_5_6k <- validateTaxa(phylo_species$x[5001:6000])
out_phylo_6_7k <- validateTaxa(phylo_species$x[6001:7000])
out_phylo_7_8k <- validateTaxa(phylo_species$x[7001:8000])
out_phylo_8_9k <- validateTaxa(phylo_species$x[8001:9000])
out_phylo_9k <- validateTaxa(phylo_species$x[9001:9478])
save.image("C:/Users/dillj/OneDrive - San Diego State University (SDSU.EDU)/Research/EcoGeoEvo/EcoGeoEvo/taxa_validation.RData")
View(phylo_species)
View(out_phylo_8_9k)
View(out_phylo_8_9k[[2]])
View(out_phylo_7_8k)
out_phylo_7_8k[[2]]
View(phylo_species)
validateTaxa <- function(taxa){
#using taxize to clean the scientific names and merge
syntaxa  <- taxize::synonyms(taxa, db = "eol", rows = 1)
df_na <- ""
df_tax <- data.frame(sub_tsn=character(),acc_name=character(),
acc_tsn=character(),acc_author=character(),
syn_author=character(),syn_name=character(),syn_tsn=character())
df_syn <- data.frame(sub_tsn =character(),acc_tsn=character(),
syn_author=character(),syn_name=character(),syn_tsn=character())
for(i in 1:length(syntaxa)){
if(i==1){bool = 0}
if(is.na(syntaxa[i])){
#vector of species not found in ITIS
df_na[length(df_na)+1] <- names(syntaxa[1])
}else{
temp <- data.frame(syntaxa[i])
if(ncol(temp) == 7){
print('here')
if(bool == 0){
#needed to make temp and change names because each df has unique column headers
df_tax_temp = temp
names(df_tax_temp) = c('sub_tsn','acc_name','acc_tsn','acc_author','syn_author','syn_name','syn_tsn')
}
else{df_tax <- rbind(df_tax,setNames(temp,names(df_tax_temp)))}
bool = bool + 1
}else{
#logic for species found. Currently have logic for correct name but with synonyms. No code present for
#correct name but no synonyms (returns 0col/0row dataframe)
#df_syn_temp = temp
#names(df_syn_temp) = c('sub_tsn','acc_tsn','syn_author','syn_name','syn_tsn')
#df_syn <- rbind(df_syn,setNames(temp,names(df_syn_temp)))
}
}
}
names(df_tax)[6] = 'species'
return(list(df_syn,df_tax,df_na))
}
test <- validateTaxa(phylo_species[1:1000])
test <- validateTaxa(phylo_species[,1:1000])
test <- validateTaxa(phylo_species[1:1000,])
?taxize
?taxize::synonyms
test< - taxize::synonyms(phylo_sepcies[1:1000,], db = "eol")
test<- taxize::synonyms(phylo_sepcies[1:1000,], db = "eol")
test<- taxize::synonyms(phylo_species[1:1000,], db = "eol")
knitr::opts_chunk$set(echo = TRUE)
system.file("data","gbif.csv",package='reader')
system.file("data","gbif.csv")
points2Poly <- function(points,x = 'x', y = 'y', species = 'species', map,
alpha = FALSE, a = 1,
type = 'All', buffer_m = 1000){
require(raster)
require(alphahull)
require(dismo)
require(rangeBuilder)
spdf <- points
#create spatialpointsdataframe
coordinates(spdf) <- ~x+y
projection(spdf) <- projection(map)
spdf@data$species <- points$species
#filtering records that are not on map (some species may be removed)
spdf <- raster::intersect(spdf,map)
#make circles around each point. D is in meters. Convert to polygon
poly_list <- list()
sp_list <- unique(spdf$species)
for( i in 1:length(sp_list)){
print(paste("Now doing", sp_list[i], i,"/",length(sp_list)))
pol <- polygons(dismo::circles(spdf[which(spdf@data$species == sp_list[i]),],
d=buffer_m,lonlat = TRUE))
projection(pol) <- projection(map)
#pol <- raster::intersect(pol,map)
pol <- raster::union(pol)
if(alpha == TRUE){
poly_coords <- matrix(ncol = 2)
for( i in 1:length((pol[1]@polygons[1][[1]]@Polygons))){
poly_coords <- rbind(poly_coords, coordinates(pol[1]@polygons[1][[1]]@Polygons[i][[1]]))
}
poly_coords <- na.omit(unique(poly_coords))
pol <- getDynamicAlphaHull(poly_coords,.90,1,buff = 1000, 3, clipToCoast = 'no')
pol <- intersect(pol[[1]], map)
poly_list[i] <- pol
poly_list[[i]]@polygons[[1]]@ID = as.character(i)
}
else{}
poly_list[i] <- pol
poly_list[[i]]@polygons[[1]]@ID = as.character(i)
}
joined = SpatialPolygons(lapply(poly_list, function(x){x@polygons[[1]]}))
jdata = SpatialPolygonsDataFrame(Sr=joined, data=data.frame(ID = 1:length(sp_list),species = sp_list),FALSE)
return(jdata)
}
require(raster)
require(alphahull)
require(dismo)
require(rangeBuilder)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
gbif <- load("data/gbif.csv")
gbif <- read.csv("data/gbif.csv")
gbif <- read.delim("data/gbif.csv", header = TRUE, sep="\t")
?read.delim
clean_gbif <- function(df, filter = NULL){
require(tidyverse)
require(CoordinateCleaner)
#filter by Genus
print(nrow(df))
df <- df[,c("gbifID","basisOfRecord","decimalLatitude","decimalLongitude",
"coordinateUncertaintyInMeters","coordinatePrecision",
"scientificName",
"class","order","family","genus","species")]
if(!is.null(filter)){
df <- filter(df, df$genus == filter)
print(nrow(df))
}
#clean blank species
df <- df %>%
filter(!is.na(df$species))
df <- df%>%
filter(df$species!= ",")
df <- df%>%
filter(df$species != "")
df <- df %>%
filter(df$species != " ")
#remove blank coordinates
df <- df %>%
filter(.$decimalLatitude != ",")%>%
filter(.$decimalLongitude != ",")
#remove records such as fossils
df <- filter(df, df$basisOfRecord == "HUMAN_OBSERVATION" |
df$basisOfRecord == 'OBSERVATION' |
df$basisOfRecord == 'PRESERVED_SPECIMEN')
df <- filter(df, is.numeric(df$coordinateUncertaintyInMeters) <= 50000)
names(df)[3:4] <- c('decimallatitude', 'decimallongitude')
#clean using CoordinateCleaner
df <- df %>%
cc_val() %>%
cc_equ() %>%
cc_cap() %>%
cc_cen() %>%
cc_gbif() %>%
cc_inst() %>%
cc_sea() %>%
cc_zero() %>%
cc_dupl()
return(df)
}
###CLeaning Data with KDE####
KDE_filter <- function(points, unispecies = TRUE, low_r = .25, up_r = .75){
###Clean using Kernel Density Estimates according to gomez 2018####
require(spatstat)
require(tidyverse)
require(raster)
if(unispecies == TRUE){
#points_clean_kde = data.frame(x,y)
win <- extent(matrix(c(points$decimallongitude,points$decimallatitude), nrow = nrow(points)))
win <- data.frame(c(win@xmin, win@xmax),
c(win@ymin, win@ymax))
win <- owin(c(win[1,1],win[2,1]),c(win[1,2],win[2,2]))
#create ppm
gbif_ppp <- ppp(points$decimallongitude,points$decimallatitude, window = win)
#KDE
gbif_kde <- density.ppp(gbif_ppp, at = "points")
gbif_kde <- data.frame(gbif_kde, gbif_ppp$x,gbif_ppp$y)
#Exclude Outliers
q <- quantile(gbif_kde$gbif_kde, probs = c(low_r,up_r))
iqr <- IQR(gbif_kde$gbif_kde)
uq <- q[1] + iqr
lq <- q[2] - iqr
gbif_kde <- gbif_kde[gbif_kde$gbif_kde <= uq,]
gbif_kde <- gbif_kde[gbif_kde$gbif_kde >= lq,]
}else{
points_clean_kde = data.frame("species" = as.character(),
'x' = as.numeric(),
'y' = as.numeric(),
"KDE_status" = as.character())
for (i in seq_along(levels(factor(points[,1])))){
print(i)
points_ <- subset(points, points[,1] == levels(factor(points[,1]))[i])
if(nrow(points_)<=5){
print(paste("Removing ", points_[1,1], " due to fewer than 5 records"))
points_merge <- data.frame('species' = points_[1,1],
'x' = points_$decimallongitude, 'y'= points_$decimallatitude,
"KDE_status" = "Removed_tooFewRecords")
points_clean_kde <- rbind(points_clean_kde,points_merge)
next
}else{
win <- extent(matrix(c(points_$decimallongitude,points_$decimallatitude), nrow = nrow(points_)))
win <- data.frame(c(win@xmin, win@xmax),
c(win@ymin, win@ymax))
win <- owin(c(win[1,1],win[2,1]),c(win[1,2],win[2,2]))
#create ppm
gbif_ppp <- ppp(points_$decimallongitude,points_$decimallatitude, window = win)
#KDE
gbif_kde <- density.ppp(gbif_ppp, at = "points")
gbif_kde <- data.frame(gbif_kde, gbif_ppp$x,gbif_ppp$y)
#Exclude Outliers
q <- quantile(gbif_kde$gbif_kde, probs = c(low_r,up_r))
iqr <- IQR(gbif_kde$gbif_kde)
uq <- q[2] + (iqr * 1.5)
lq <- q[1] - (iqr * 1.5)
gbif_kde <- gbif_kde[gbif_kde$gbif_kde <= uq,]
gbif_kde <- gbif_kde[gbif_kde$gbif_kde >= lq,]
nrow(gbif_kde)
if(nrow(gbif_kde)<=1){
print(paste(points_[1,1], " removed following filtering "))
points_merge <- data.frame('species' = points_[1,1],
'x' = points_$decimallongitude, 'y'= points_$decimallatitude,
"KDE_status" = "Removed_KDE_RemovedAll")
points_clean_kde <- rbind(points_clean_kde,points_merge)
next
}else{
print(paste('Adding ',points_[1,1]))
points_merge <- data.frame('species' = points_[1,1],
'x' = gbif_kde$gbif_ppp.x, 'y'= gbif_kde$gbif_ppp.y,
"KDE_status" = "Filter_Successful")
points_clean_kde <- rbind(points_clean_kde,points_merge)
}
}
}
}
return(points_clean_kde)
}
gbif_raw <- read.delim("data/gbif.csv", header = TRUE, sep="\t")
gbif <- clean_gbif(.)%>%
KDE_filter(., FALSE)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(tidyverse)
gbif <- clean_gbif(.)%>%
KDE_filter(., FALSE)
gbif_raw <- read.delim("data/gbif.csv", header = TRUE, sep="\t")
gbif <- clean_gbif(gbif_raw)%>%
KDE_filter(., FALSE)
gbif_raw <- read.delim("data/gbif.csv", header = TRUE, sep="\t")
gbif_1 <- clean_gbif(gbif_raw)
df_kde <- data.frame(species = gbif_raw$species,
decimallongitude = gbif_raw$decimallongitude,
decimallatitude = gbif_raw$decimallatitude)
df_kde <- data.frame(species = gbif_1$species,
decimallongitude = gbif_1$decimallongitude,
decimallatitude = gbif_1$decimallatitude)
gbif_2 <- KDE_filter(gbif_1,FALSE)
View(df_kde)
?KDE_filter
###CLeaning Data with KDE####
KDE_filter <- function(points, unispecies = TRUE, low_r = .25, up_r = .75, rec_min = 5){
###Clean using Kernel Density Estimates according to gomez 2018####
require(spatstat)
require(tidyverse)
require(raster)
if(unispecies == TRUE){
#points_clean_kde = data.frame(x,y)
win <- extent(matrix(c(points$decimallongitude,points$decimallatitude), nrow = nrow(points)))
win <- data.frame(c(win@xmin, win@xmax),
c(win@ymin, win@ymax))
win <- owin(c(win[1,1],win[2,1]),c(win[1,2],win[2,2]))
#create ppm
gbif_ppp <- ppp(points$decimallongitude,points$decimallatitude, window = win)
#KDE
gbif_kde <- density.ppp(gbif_ppp, at = "points")
gbif_kde <- data.frame(gbif_kde, gbif_ppp$x,gbif_ppp$y)
#Exclude Outliers
q <- quantile(gbif_kde$gbif_kde, probs = c(low_r,up_r))
iqr <- IQR(gbif_kde$gbif_kde)
uq <- q[1] + iqr
lq <- q[2] - iqr
gbif_kde <- gbif_kde[gbif_kde$gbif_kde <= uq,]
gbif_kde <- gbif_kde[gbif_kde$gbif_kde >= lq,]
}else{
points_clean_kde = data.frame("species" = as.character(),
'x' = as.numeric(),
'y' = as.numeric(),
"KDE_status" = as.character())
for (i in seq_along(levels(factor(points[,1])))){
print(i)
points_ <- subset(points, points[,1] == levels(factor(points[,1]))[i])
if(nrow(points_)<= rec_min){
print(paste("Removing ", points_[1,1], " due to fewer than ", recmin, " records"))
points_merge <- data.frame('species' = points_[1,1],
'x' = points_$decimallongitude, 'y'= points_$decimallatitude,
"KDE_status" = "Removed_tooFewRecords")
points_clean_kde <- rbind(points_clean_kde,points_merge)
next
}else{
win <- extent(matrix(c(points_$decimallongitude,points_$decimallatitude), nrow = nrow(points_)))
win <- data.frame(c(win@xmin, win@xmax),
c(win@ymin, win@ymax))
win <- owin(c(win[1,1],win[2,1]),c(win[1,2],win[2,2]))
#create ppm
gbif_ppp <- ppp(points_$decimallongitude,points_$decimallatitude, window = win)
#KDE
gbif_kde <- density.ppp(gbif_ppp, at = "points")
gbif_kde <- data.frame(gbif_kde, gbif_ppp$x,gbif_ppp$y)
#Exclude Outliers
q <- quantile(gbif_kde$gbif_kde, probs = c(low_r,up_r))
iqr <- IQR(gbif_kde$gbif_kde)
uq <- q[2] + (iqr * 1.5)
lq <- q[1] - (iqr * 1.5)
gbif_kde <- gbif_kde[gbif_kde$gbif_kde <= uq,]
gbif_kde <- gbif_kde[gbif_kde$gbif_kde >= lq,]
nrow(gbif_kde)
if(nrow(gbif_kde)<=1){
print(paste(points_[1,1], " removed following filtering "))
points_merge <- data.frame('species' = points_[1,1],
'x' = points_$decimallongitude, 'y'= points_$decimallatitude,
"KDE_status" = "Removed_KDE_RemovedAll")
points_clean_kde <- rbind(points_clean_kde,points_merge)
next
}else{
print(paste('Adding ',points_[1,1]))
points_merge <- data.frame('species' = points_[1,1],
'x' = gbif_kde$gbif_ppp.x, 'y'= gbif_kde$gbif_ppp.y,
"KDE_status" = "Filter_Successful")
points_clean_kde <- rbind(points_clean_kde,points_merge)
}
}
}
}
return(points_clean_kde)
}
gbif_2 <- KDE_filter(gbif_1,FALSE, rec_min = 1)
###CLeaning Data with KDE####
KDE_filter <- function(points, unispecies = TRUE, low_r = .25, up_r = .75, rec_min = 5){
###Clean using Kernel Density Estimates according to gomez 2018####
require(spatstat)
require(tidyverse)
require(raster)
if(unispecies == TRUE){
#points_clean_kde = data.frame(x,y)
win <- extent(matrix(c(points$decimallongitude,points$decimallatitude), nrow = nrow(points)))
win <- data.frame(c(win@xmin, win@xmax),
c(win@ymin, win@ymax))
win <- owin(c(win[1,1],win[2,1]),c(win[1,2],win[2,2]))
#create ppm
gbif_ppp <- ppp(points$decimallongitude,points$decimallatitude, window = win)
#KDE
gbif_kde <- density.ppp(gbif_ppp, at = "points")
gbif_kde <- data.frame(gbif_kde, gbif_ppp$x,gbif_ppp$y)
#Exclude Outliers
q <- quantile(gbif_kde$gbif_kde, probs = c(low_r,up_r))
iqr <- IQR(gbif_kde$gbif_kde)
uq <- q[1] + iqr
lq <- q[2] - iqr
gbif_kde <- gbif_kde[gbif_kde$gbif_kde <= uq,]
gbif_kde <- gbif_kde[gbif_kde$gbif_kde >= lq,]
}else{
points_clean_kde = data.frame("species" = as.character(),
'x' = as.numeric(),
'y' = as.numeric(),
"KDE_status" = as.character())
for (i in seq_along(levels(factor(points[,1])))){
print(i)
points_ <- subset(points, points[,1] == levels(factor(points[,1]))[i])
if(nrow(points_)<= rec_min){
print(paste("Removing ", points_[1,1], " due to fewer than ", rec_min, " records"))
points_merge <- data.frame('species' = points_[1,1],
'x' = points_$decimallongitude, 'y'= points_$decimallatitude,
"KDE_status" = "Removed_tooFewRecords")
points_clean_kde <- rbind(points_clean_kde,points_merge)
next
}else{
win <- extent(matrix(c(points_$decimallongitude,points_$decimallatitude), nrow = nrow(points_)))
win <- data.frame(c(win@xmin, win@xmax),
c(win@ymin, win@ymax))
win <- owin(c(win[1,1],win[2,1]),c(win[1,2],win[2,2]))
#create ppm
gbif_ppp <- ppp(points_$decimallongitude,points_$decimallatitude, window = win)
#KDE
gbif_kde <- density.ppp(gbif_ppp, at = "points")
gbif_kde <- data.frame(gbif_kde, gbif_ppp$x,gbif_ppp$y)
#Exclude Outliers
q <- quantile(gbif_kde$gbif_kde, probs = c(low_r,up_r))
iqr <- IQR(gbif_kde$gbif_kde)
uq <- q[2] + (iqr * 1.5)
lq <- q[1] - (iqr * 1.5)
gbif_kde <- gbif_kde[gbif_kde$gbif_kde <= uq,]
gbif_kde <- gbif_kde[gbif_kde$gbif_kde >= lq,]
nrow(gbif_kde)
if(nrow(gbif_kde)<=1){
print(paste(points_[1,1], " removed following filtering "))
points_merge <- data.frame('species' = points_[1,1],
'x' = points_$decimallongitude, 'y'= points_$decimallatitude,
"KDE_status" = "Removed_KDE_RemovedAll")
points_clean_kde <- rbind(points_clean_kde,points_merge)
next
}else{
print(paste('Adding ',points_[1,1]))
points_merge <- data.frame('species' = points_[1,1],
'x' = gbif_kde$gbif_ppp.x, 'y'= gbif_kde$gbif_ppp.y,
"KDE_status" = "Filter_Successful")
points_clean_kde <- rbind(points_clean_kde,points_merge)
}
}
}
}
return(points_clean_kde)
}
gbif_2 <- KDE_filter(gbif_1,FALSE, rec_min = 1)
gbif_2 <- KDE_filter(df_kde,FALSE, rec_min = 3)
load_all()
devtools::load_all()
install.packages('devtools')
install.packages("devtools")
library(devtools)
install.packages('cli')
install.packages('cli')
install.packages("cli")
install.packages("cli")
install.packages("cli")
devtools::load_all()
devtools::load_all()
devtools::load_all()
devtools::load_all()
rm(list = c("clean_gbif", "KDE_filter", "points2Poly"))
devtools::load_all()
devtools::load_all()
devtools::load_all()
require(raster)
require(alphahull)
require(dismo)
require(rangeBuilder)
#'Create circles around points and/or alpha polygons(NEED TO TEST)
#'
#'Points as a dataframe with columns species, x, and y
#'map created from map function (used to crop the circles to a landmass)
#'
#'
rm(list = all())
#'Create circles around points and/or alpha polygons(NEED TO TEST)
#'
#'Points as a dataframe with columns species, x, and y
#'map created from map function (used to crop the circles to a landmass)
#'
#'
data("gbif")
#'Create circles around points and/or alpha polygons(NEED TO TEST)
#'
#'Points as a dataframe with columns species, x, and y
#'map created from map function (used to crop the circles to a landmass)
#'
#'
data("gbif", gbif)
#'Create circles around points and/or alpha polygons(NEED TO TEST)
#'
#'Points as a dataframe with columns species, x, and y
#'map created from map function (used to crop the circles to a landmass)
#'
#'
data(gbif)
#'Create circles around points and/or alpha polygons(NEED TO TEST)
#'
#'Points as a dataframe with columns species, x, and y
#'map created from map function (used to crop the circles to a landmass)
#'
#'
data("gbif")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(tidyverse)
gbif_raw <- read.delim("data/gbif.csv", header = TRUE, sep="\t")
gbif_raw <- read.delim("data/gbif.csv", header = TRUE, sep="\t")
save(gbif_raw, "data/gbif")
save("data/gbif",gbif_raw)
save(gbif_raw)
save(gbif_raw, file = "data/gbif.csv")
save(gbif_raw, file = "data/gbif.Rdata")
load_all()
devtools::load_all()
load_all()
devtools::load_all()
devtools::load_all()
data("gbif")
devtools::load_all()
data("gbif")
gbif_raw <- read.delim("data/gbif.csv", header = TRUE, sep="\t")
gbif_raw <- read.delim("data/gbif.csv", header = TRUE, sep="\t")
load('data/gbif.Rdata')
df <- load('data/gbif.Rdata')
load("C:/Users/dillj/OneDrive - San Diego State University (SDSU.EDU)/Research/EcoGeoEvo/EcoGeoEvo/data/gbif.Rdata")
View(gbif_raw)
force(gbif_raw)
gbif_raw <- read.delim("data/gbif.csv", header = TRUE, sep=",")
gbif_raw <- read.delim("data/gbif.csv", header = TRUE, sep="\t")
gbif_raw <- read.delim("data/gbif.csv", header = TRUE, sep="/t")
df <- load('data/gbif.Rdata')
gbif_raw <- read.delim("data/gbif.csv", header = TRUE, sep="/t")
gbif_raw <- read.delim("data/gbif.csv", header = TRUE, sep="\t")
devtools::document()
devtools::document()
